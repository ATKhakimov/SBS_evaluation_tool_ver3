Раздел 4.1. Качество работы алгоритма
Тест 4.1.1. Доверительный интервал метрики качества на валидации
Цель теста. Оценка ключевой метрики модели. Анализ соответствия метрики значения бизнес-требованиям, выставленным владельцем модели.
Описание расчетов. Проводится комплексная оценка метрики качества модели на валидационной выборке с учетом бизнес-процесса. На первом этапе рассчитывается ключевая метрика, заданная для валидируемой модели. Расчет производится в соответствии с выбранной схемой валидации. В случае кросс-валидации светофор выставляется на основании среднего значения на тестовых фолдах. В случае небольшого количества наблюдений (устанавливается экспертно) тест выполняется путем многократного разбиения на тренировочную и тестовые выборки с последующим усреднением метрики и построением распределения на основании полученных значений. В случае мультиклассовой классификации, дополнительно учитывается метрика по отдельным классам, чтобы избежать расчета ключевой метрики по доминирующему классу.
Иллюстрация: Приводится таблица со средним значением ключевой и дополнительных метрик (при необходимости).
F1_score (ключевая метрика)	0.65
Precision	0.7
Recall	0.6
Для задач регрессии в иллюстративных целях добавляется информативный график (scatter plot), показывающий зависимость между предсказанными и реальными значениями целевой переменной.

Также для задач классификации в качестве иллюстрации могут быть приведены графики Precision-Recall для классов или другие показательные графики.
Следующим шагом выполнения теста является построение распределения ключевой метрики в результате проведения бутстрапирования (не менее 300 итераций). Происходит проверка адекватности границ разброса качества и сравнение полученных результатов с Baseline, Dummy-моделью, а также метрикой предыдущей версии модели (при наличии).
Выявленные в рамках данного теста недостатки могут свидетельствовать о нестабильности модели и возможном снижении ожидаемого финансового эффекта от внедрения модели, т.е росте модельного риска.
Иллюстрация: Приводится таблица и график распределения, в которых указывается значение метрики качества разработчика и Dummy модели, среднее значение, а также 5% и 95%-е квантили, полученные в результате бутстрапирования.

Parameters	Original model	Mean bootstrap	Left_95.0_interval	Right_95.0_interval	Dummy model
Value	0.978	0.978	0.973	0.982	0.500
Probability	0.503	0.500	0.025	0.975	0.500

Интерпретация результатов. Результат по тесту выставляется исходя из величины соответствующей границы доверительного интервала ключевой метрики (для метрик «чем больше, тем лучше» – левой границы, «чем меньше, тем лучше» – правой), а также с учетом выставленных требований со стороны бизнес-процесса при их наличии. Если метрика зависит от дисбаланса классов и/или количества наблюдений в положительном классе (например, average precision), то на усмотрение валидатора светофор может быть скорректирован. При отсутствии названия метрики в таблице «Границы допустимых значений для различных метрик», границы светофора определяются ближайшей похожей по интерпретации. Если есть информация, что бизнес-заказчиком установлено минимальное значение метрики, данный факт может учитываться при определении границ светофора. В случае, если результат получил красный сигнал светофора, при этом бизнес-заказчик удовлетворен данным результатом, сигнал светофора заменяется на желтый с целью предупреждения о низком значении ключевой метрики.
Допустимые значения соответствующей границы 95% доверительного интервала
	Метрики		
	Коэффициент Джини	F1/Precision/Recall	MAPE
	Менее 20%	Менее 50%	Более 50%
	Не удовлетворяет требованиям бизнес-процесса		
	20% – 40%	50% – 70%	20% – 50%
	Более 40%	Более 70%	Менее 20%

Тест 4.1.2. Проверка на недостаточность количества наблюдений
Цель теста. Убедиться, что количество наблюдений является достаточным для обучения используемого алгоритма.
Тест проводится при первичной валидации.
Описание расчетов. Проанализировать зависимость доли наблюдений, участвующих в обучении, и метрики качества на тесте.
Строится зависимость изменения среднего значения и дисперсии метрики при добавлении наблюдений. Шаг увеличения доли наблюдений – 10%.
Если наблюдается положительный тренд, то потенциально существует возможность улучшения метрики при увеличении размера выборки для разработки. При этом, если при приближении доли наблюдений к 100% значение метрики качества выходит на плато, можно сделать вывод о достаточности количества наблюдений.
Иллюстрация: Приводится график зависимости метрики качества на валидационной выборке для каждого шага увеличения доли наблюдений, участвующих в обучении, а также ее доверительный интервал (5% и 95% квантили).


Интерпретация результатов. Тест является информативным.

Тест 4.1.3. Соответствие наблюдаемого и предсказанного таргета в целом по выборке и в разрезе бакетов (калибровка модели)
Цель теста. Определить, насколько точно модель прогнозирует вероятность целевого события и есть ли смещение прогнозируемой величины в целом по выборке и в разбивке по бакетам.
Тест не проводится, если целью модели является ранжирование наблюдений и не используется прогноз вероятности.
Описание расчетов.
Описание теста приведено в Приложении 2 в Методике валидации рисковых моделей бинарной классификации на основе логистической регрессии (см. п. 5.8, Приложение 6).
Проверяется нулевая гипотеза и том, что модель классификации калибрована.
1. Строится калибровочная кривая модели и кривая идеально калиброванного классификатора, чем ближе первая кривая ко второй, тем выше качество калибровки модели. 
2. Строится бустрапированная оценка качества калибровки модели и правая граница доверительного интервала с заданным уровнем значимости, считается p-value калибровки. Также изображается на графике качество калибровки необученной (рандомной) модели.
В случае проведения теста в разрезе бакетов целевая переменная делится на последовательные равномерные интервалы, для каждого из которых оценивается соответствие наблюдаемого и предсказанного уровня целевой переменной. Считается доля вылетов за пределы 95% и 99% межквантильных размахов (количество бакетов выбирается экспертно).
Иллюстрация: полигон с бакетами, calibration curve и/или гистограмма распределения по усмотрению валидатора.



Интерпретация результатов. Тест носит информативный характер.
Раздел 4.2. Стабильность результатов работы модели
Тест 4.2.1. Наличие переобучения
Цель теста. Выявление факта переобучения модели.
Описание расчетов. Рассчитывается ключевая метрика, заданная для валидируемой модели. Расчет производится в соответствии с выбранной схемой валидации для тренировочных и тестовых фолдов. Затем производится сравнение метрики качества на тренировочных и тестовых выборках путем вычисления относительной разницы между ними.
Иллюстрация. Результат оформляется в виде таблицы со значением ключевой метрики на различных фолдах, а также величины относительного повышения ошибки.
F1 score (Train)	F1 score (Test)	Относительное изменение метрики, %
0.77	0.70	-9.1%
Валидатор также имеет возможность дополнительно указать причину возможного переобучения, исходя из других тестов.
Интерпретация результатов. Светофор выставляется исходя из относительного изменения метрики между тренировочными и тестовыми фолдами. В случае, если результат получил красный сигнал светофора и отсутствует альтернативная модель, которая сохраняет качество ключевой метрики и сокращает относительное повышение ошибки на валидации, сигнал светофора заменяется на желтый.
	Критерий
	Относительное ухудшение метрики на валидации составляет более 50%
	Относительное ухудшение метрики на валидации составляет менее 50%, но более 30%
	Относительное ухудшение метрики на валидации составляет менее 30%

Тест 4.2.2. Стабильность метрики в динамике
Цель теста. Выявление временных периодов, на которых качество модели заметно снижается.
Описание расчетов. Анализируется качество ключевой метрики модели в динамике.
При выявлении нестабильности модели может быть построен временной тренд для анализа ожидаемых в следующих периодах значений метрики качества.
Иллюстрация: строится полигон: дата (временной срез) против значения метрики с иллюстрацией доверительных интервалов, рассчитанных в тесте 4.1.1.

Интерпретация результатов. Тест проводится информативно, при этом в случае существенной волатильности метрики это может послужить основанием для проведения дополнительного анализа модели, например, исследование данных на наличие пропусков/аномалий.

Тест 4.2.3. Качество в разрезе категорий
Цель теста. Проверка способности модели хорошо предсказывать целевую переменную для всех ключевых сегментов. Выявление важных категорий, на которых модель работает хуже.
Описание расчетов. Производится расчет метрики в группах, разделенных по значениям категориального признака, и ее сопоставление с метрикой на всей выборке:
1. Валидатор выбирает по своему усмотрению важный категориальный признак и группирует по его значениям объекты из выборки.
2. Вычисляется метрика для каждой группы объектов.
3. Сравнивается значение с исходной метрикой и доверительным интервалом из теста 4.1.1.
Тест проводится при наличии важных категорий, которые сильно различаются, например, по вкладу в бизнес метрику (бизнес-сегмент, отрасль, регион присутствия) и др.).
Ожидается, что метрики в группах будут принимать схожие значения по сравнению с метрикой на всех данных (попадут в доверительный интервал).
Результаты данного теста могут быть учтены в рамках альтернативного моделирования (пункт 4.4.7. Модели для отдельных категорий).
Иллюстрация. Приводится таблица или график со значениями метрик качества в выделенных категориях с указанием доверительных интервалов из теста 4.1.1.

metric	metric_train	%_train	metric_test	%_test
Метрика_модели	0.796	100.00%	0.828	100.00%
Крупнейшие	0.747	5.52%	0.725	4.50%
Крупные	0.757	18.60%	0.832	19.50%
Средние	0.809	75.88%	0.832	76.00%

Интерпретация результатов. Тест приводится информативно.
Раздел 4.3. Качество отбора признаков и интерпретационный анализ
Тесты из данного раздела проводятся только при первичной валидации.
Тест 4.3.1. Сравнение Shap importance признаков на обучении и валидации
Цель теста. Оценить влияние и степень изменения значимости для каждого из факторов между тренировочными и тестовыми выборками.
Описание расчетов. Проводится оценка эффективности ранжирования отдельных факторов. Для каждого из факторов вычисляется shap importance для тестовых и тренировочных выборок, после чего вычисляется абсолютная и относительная разница полученных значений по следующей формуле:



Графическая визуализация. Строится столбчатая диаграмма для топ-m признаков (m на усмотрение ответственного валидатора), характеризующая среднее значение shap importance для признаков модели, начиная с наиболее важного. Приводится таблица с названием фактора и значениями shap importance тренировочных и тестовых фолдов и их разницей.

	Shap imp. train	Shap imp. test	Shap imp. diff	Shap imp. diff, %
cred_application_cnt_industry_dist_to_max_tax_income_year18	0.006324	0.008422	0,002098	33,1752%
tax_income_year18	0.004253	0.006444	0,002191	51,5166%
cred_application_cnt_industry_dist_from_mean_tax_income_year18	0.003685	0.004067	0,000382	10,3664%
tax_income	0.002588	0.002479	-0,000109	-4,2117%
industry_divided_by_sum_tax_income_year18	0.001601	0.002069	0,000468	29,2317%
...	...	...	,,,	,,,
wlt_prediction_divided_by_5_nearest_neighbors	0.000471	-0.000104	-0,000575	-122,0807%
cred_application_cnt_divided_by_max_total_sum_kt_year18	0.000151	-0.000119	-0,00027	-178,8079%
cred_application_cnt_dist_from_mean_tax_income_year18	0.000190	-0.000132	-0,000322	-169,4737%
industry_dist_to_max_total_sum_kt_year18	0.000210	-0.000159	-0,000369	-175,7143%
industry_normed_by_min_max_wlt_prediction	0.000138	-0.000159	-0,000297	-215,2174%
				
				
				
				
				
				

Интерпретация результатов. Результат за данный тест определяется исходя из доли факторов с изменением значимости по модулю более чем на 50%. При наличии двух тестовых выборок выставление светофора происходит по результатам на OOT выборке.
	Критерий
	Более 80% признаков имеют падение значимости более 50% по сравнению с тренировочными фолдами.
	Более 50% но менее 80% признаков имеют падение значимости более 50% по сравнению с тренировочными фолдами.
	Менее 50% признаков имеют падение значимости более 50% по сравнению с тренировочными фолдами.
Тест 4.3.2. Адекватность вклада признаков
Цель теста. Интерпретация работы модели.
В рамках данного теста проводится интерпретация вклада факторов в итоговый результат работы модели. Проводится проверка, отвергаются ли предположения о вкладе конкретных признаков в модели в соответствии со смыслом целевой переменной.
Описание расчетов. В рамках более детального анализа предыдущих пунктов осуществляется анализ вклада каждого отдельного фактора в итоговый скор модели. Проводится поиск контрпримера адекватности модели. Например, добавив ко всей базе 1 год к возрасту, мы получаем снижение склонности к страховке, что противоречит логике использования модели в бизнес-процессе.
Интерпретация результатов. Тест приводится информативно и для выборочных моделей.

Тест 4.3.3. Наличие избыточных и неинформативных признаков (uplift test)
Цель теста. Изучается возможность избавления от шумных или неинформативных признаков с целью повышения качества и стабильности модели. Выделить факторы, не вносящие вклад в улучшении метрики при обучении алгоритма разработчика.
Тест не проводится при периодической валидации.
Описание расчетов. В качестве алгоритма определения значимости признаков используется shap importance. Валидатором может быть проведен альтернативный расчет значимости признаков с помощью методов forward selection и backward selection. Затем происходит обучение алгоритма разработчика на наборах признаков, составленных путем последовательного добавления факторов в порядке их значимости. При большом числе факторов может быть выбран больший шаг (число добавляющихся на каждом шаге факторов), но при этом сокращение количества итераций обучения модели не должно уменьшать информативность теста.
Иллюстрация: Uplift-кривая для выборок train и valid (при наличии), по оси OX отражается количество признаков, вошедших в модель, по оси OY – качество модели, обученной на соответствующих признаках. Дополнительно информативно на графике может приводиться uplift-кривая для остальных выборок (oos/oot).

Интерпретация результатов. Светофор выставляется исходя эффекта от удаления не вносящих вклад в прирост метрики признаков на валидационной выборке (valid), а при ее отсутствии – на train.
	Критерий
	В 99%-ый доверительный интервал разницы метрик качества на тестовой выборке не попадает 0 (при улучшении метрики).
	В 95%-ый доверительный интервал разницы метрик качества не попадает 0 (при улучшении метрики).
	Ноль попадает в 95%-ый доверительный интервал разницы метрик качества.
ИЛИ
Незначимые признаки не выявлены

Тест 4.3.4. Влияние пропущенных значений на результаты работы модели
Цель теста. Изучить влияние пропусков в признаках на качество модели. Найти признаки, от которых существенно зависят предсказания модели и наличие пропусков в которых существенно понижает качество.
Тест моделирует ситуации, когда наиболее значимые признаки имеют наихудший процент пропусков из возможных на выборке для обучения.
Тест не проводится при периодической валидации.
Описание расчетов. Оценивается влияние роста доли пропусков путем сравнения средней ошибки на данных с пропусками и без пропусков.
1. Оцениваем, какие из наиболее важных для модели признаков имеют пропуски на обучающей выборке. Если в данных нет пропусков, то тест не применим.
2. Задаем параметр n_iterations – сколько раз мы будем добавлять пропуски в признак для построения графика и сколько раз добавлять пропуски во все признаки для выставления светофора.
3. Разбиваем на фолды по дате (или на случайные фолды в случае отсутствия временной составляющей) и находим самый высокий процент пропусков на фолде. Строим график, добавляя для каждого признака пропуски до максимально возможного из разбивки по фолдам. Так мы моделируем ситуацию наихудшего случая для признака и смотрим при этом падение метрики качества.
4. Ожидается, что добавление пропусков приведет к ухудшению метрики для наиболее важных фичей. Если график показывает улучшение при добавлении пропусков, это может указывать на то, что мы заменили пропусками плохо обрабатываемые моделью значения, и она перестала на них ошибаться.
5. Добавляем n_iterations раз пропуски во все признаки до найденного максимального процента пропусков по каждому признаку. Усредняем значение метрики, вычисляем относительную разницу с метрикой на данных без пропусков.
Существенное изменение результатов работы модели при исключении из нее или добавлении пропущенных наблюдений может свидетельствовать о ее нестабильности и риске роста ошибки прогноза при изменении доли таких наблюдений.
В случае наличия в данных более 10% пропусков проводится дополнительный анализ – стресс-тестирование. При проведении стресс-тестирования для каждого признака с большой долей пропусков последовательно увеличивается доля пропусков с шагом 5% и оценивается падение качества модели.
Иллюстрация: Значение метрики при выравнивании процента пропусков по фолду с максимальным количеством пропусков. Таблица с долей пропусков по каждому признаку.

columns	mean	std	min	25%	50%	75%	max
active_deals_lm_1y_ago	0.591	0.000	0.591	0.591	0.591	0.591	0.591
ostatok_sum_holding_lm_pm	0.575	0.002	0.573	0.573	0.573	0.577	0.577
ostatok_sum_lm_3m	0.525	0.017	0.510	0.510	0.523	0.530	0.563
В случае, если проводилось дополнительное стресс-тестирование, строится полигон зависимости метрики качества от количества пропусков в признаке.

Интерпретация результатов. Оценивается относительное изменение метрики качества при наличии 50% пропусков по фактору относительно метрики на данных без пропусков.
	Критерий
	Падение целевой метрики составляет >= 20% при выравнивании пропусков по фолду с наибольшим количеством пропусков.
	Падение целевой метрики составляет >= 10%, но < 20% при выравнивании пропусков по фолду с наибольшим количеством пропусков.
	Падение целевой метрики составляет менее 10% при выравнивании пропусков по фолду с наибольшим количеством пропусков.
4.4.4. Альтернативный отбор факторов
Цель. Изучить возможность повышения качества и стабильности модели за счет изменения набора входящих в модель признаков.
Описание расчетов. Воронка отбора признаков состоит из четырех этапов.
1.	1. Корреляция признаков с таргетом
Цель. Выявление линейных взаимосвязей факторов и таргета.
1. Вычисляется корреляция на основе проверки гипотезы Пирсона о независимости двух переменных (библиотека phi_k).
2. Строится корреляция для топ-важных признаков.
3. Ожидается, что все топ-признаки по значимости будут иметь ненулевую корреляцию с таргетом.
Признаки с высокой линейной корреляцией рекомендуются к использованию при построении альтернативной интерпретируемой модели линейной регрессии.
Слишком большие значения коэффициента корреляции могут говорить о наличии ликов и служат поводом для дополнительного анализа.
1.	2. Корреляция признаков
Цель. Оценить коррелированность каждого фактора с совокупностью остальных факторов по коэффициенту корреляции Пирсона.
Проверяется гипотеза о некоррелированности признаков в модели. Избыточность количества признаков потенциально может привести к размытию показателя важности признаков, увеличению времени расчетов и используемой памяти, а также некорректной работе модели. При обнаружении данной проблемы (наличие факторов с парной корреляцией больше некоторого порога, например, 0.95) предлагается удалить скоррелированные признаки.
В качестве иллюстрации приводится матрица корреляции признаков (при большом количестве признаков диаграмма строится только для наиболее важных факторов).

1.	3. VIF
Цель. Проверка признаков на взаимную зависимость с целью выявления избыточных факторов (таких, что их удаление не приведет к снижению качества модели).
1. Для вычисления линейной зависимости необходимо убрать все строки, содержащие пустые значения. При малом количестве строк без пропусков тест неприменим.
2. Вычисляется фактор инфляции дисперсии (VIF) как 1/(1-R2), где R2 – коэффициент детерминации линейной зависимости фактора от остальных признаков.
3. Ожидается, что все факторы будут иметь VIF около 0.
1.	4. Двухлесовой отбор
Цель. Поиск наиболее важных и стабильных признаков.
Для каждого признака вычисляется p-value следующим способом:
1. Обучающая выборка делится на две части. На первой части строится случайный лес (RF) и вычисляется коэффициент важности по среднему совпадающих предсказаний с таргетом на второй части выборки.
2. На первой части выборки производится перемешивание, снова строится RF вычисляется коэффициент важности на второй части выборки.
3. Вычисляется разность начального и перемешенного коэффициента важности. Рекомендуемое повторение шага 2 и 3 – 300 раз.
4. Шаги 1-3 повторяются с построением RF на второй части и проверкой на первой части выборки.
5. Из вычисленных разниц берутся отрицательные и нулевые скоры. Множество положительных скоров важности строится как отрицательное с противоположным знаком.
6. P-value определяется как 1-CDF() на указанных в шаге 5 множествах.
Ожидается, что диаграмма будет симметричной относительно 0, а на втором графике точки будут распределены вдоль осей в первом и третьем квадрате, то есть разница важностей должна иметь один знак на обеих подвыборках.
Интерпретация результатов. Результаты могут быть применены в качестве одного из шагов при построении альтернативной модели.

4.4.5. Анализ кривых обучения
Цель. Выявление недообучения или переобучения модели путем построения кривых обучения.
Описание расчетов. Факт наличия переобучения/недообучения проверяется с помощью анализа кривых обучения. Производится построение кривых обучения модели (график зависимости значения функции потерь при обучении и валидации от количества итераций). На усмотрение валидатора вместо функции потерь график может строиться по значениям ключевой метрики.
При выявлении недообучения или переобучения модели количество итераций алгоритма может быть соответственно увеличено или уменьшено в ходе альтернативного моделирования.
Тест проводится при наличии выборки valid.
В случае, если для воспроизведения обучения модели требуются повышенные затраты машинного времени или построение кривых обучения нецелесообразно для используемого алгоритма, тест может не проводиться.
Иллюстрация. Результат оформляется в виде графика кривых обучения.
Интерпретация результатов. Тест проводится информативно

Глава 5. Правила выставления итогового светофора
Определение результатов по блокам тестов количественного анализа
Цвет	Качество работы алгоритма	Стабильность результатов работы модели	Качество отбора признаков и интерпретационный анализ	Альтернативное моделирование
Красный	Наличие красного цвета хотя бы по одному тесту.	Наличие красного цвета хотя бы по одному тесту.	Наличие красного цвета хотя бы по одному тесту.	За тест 4.4.11 выставлен красный светофор.
Желтый	Есть желтые маркеры; отсутствуют красные маркеры.	Есть желтые маркеры; отсутствуют красные маркеры.	Есть желтые маркеры; отсутствуют красные маркеры.	За тест 4.4.11 выставлен желтый светофор.
Зеленый	В остальных случаях.	В остальных случаях.	В остальных случаях.	В остальных случаях.
Итоговый светофор за количественный анализ для OOS выборки выставляется на основании худшего светофора из блоков «Качество работы алгоритма», «Стабильность результатов работы модели», «Качество отбора признаков и интерпретационный анализ» и «Альтернативное моделирование». При валидации на выборке OOT итоговый светофор выставляется согласно схеме ниже.
Определение итогового светофора за количественный анализ для OOT выборки
	Худший результат по разделам «Качество работы алгоритма» и «Альтернативное моделирование»			
	Зеленый	Желтый	Красный	
Худший результат по разделам «Стабильность результатов работы модели» и «Качество отбора признаков и интерпретационный анализ»	Зеленый	Зеленый	Желтый	Красный
	Желтый	Желтый	Желтый	Красный
	Красный	Желтый	Красный	Красный

Правила выставления итогового светофора за валидацию модели
Итоговый светофор за валидацию модели выставляется на основании худшего светофора из блоков «Качественный анализ», «Анализ данных», «Количественный анализ».



Приложение 1. Определение расчетных метрик и формул, используемых при валидации

Параметр/метрика/
тест	Методика расчета, интерпретация показателей
	Точность предсказаний модели рассчитывается по формуле:

где  — истинно-положительное решение,  — ложно-положительное решение.
	Полнота предсказаний модели рассчитывается по формуле:

где  — истинно-положительное решение,  — ложно-отрицательное решение.
f1-мера	Для модели, решающей задачу бинарной классификации, f1-мера представляет собой среднее гармоническое между точностью и полнотой. Рассчитывается по формуле:
,
где  — точность модели,  — полнота модели.
Коэффициент детерминации	Коэффициент детерминации  рассчитывается как
,
где  – сумма квадратов остатков регрессии, - фактические и прогнозные значения объясняемой переменной, - общая сумма квадратов,
MAPE (Средняя абсолютная относительная ошибка)	Вычисляется значение метрики по следующей формуле:

где - фактические и прогнозные значения объясняемой переменной
SMAPE (Симметричная средняя абсолютная относительная ошибка)	Вычисляется значение метрики по следующей формуле:
,
где - фактические и прогнозные значения объясняемой переменной.
MSE (Cреднеквадратичная ошибка)	Вычисляется значение метрики по следующей формуле:
,
где - фактические и прогнозные значения объясняемой переменной.
RMSE (Корень из среднеквадратичной ошибки)	Вычисляется значение метрики по следующей формуле:
,
где - фактические и прогнозные значения объясняемой переменной.
MAE (Средняя абсолютная ошибка)	Вычисляется значение метрики по следующей формуле:
,
где - фактические и прогнозные значения объясняемой переменной.
macro-метрика	Пусть решается задача множественной классификации и количество классов равно N. Рассмотрим N задач бинарной классификации, в которых решается задача определения одного из исходных классов, а все остальные классы объединяются в общий второй класс. Для каждой из этих N задач можно посчитать бинарные метрики качества и различные характеристики (). При макро-усреднении сначала вычисляется итоговая метрика для каждого класса, а затем результаты усредняются по всем классам. Например, точность модели вычисляется по следующей формуле:

где
micro-метрика	Пусть решается задача множественной классификации и количество классов равно N. Рассмотрим N задач бинарной классификации, в которых решается задача определения одного из исходных классов, а все остальные классы объединяются в общий второй класс. Для каждой из этих N задач можно посчитать бинарные метрики качества и различные характеристики (). При микро-усреднении сначала усреднение происходит по всем характеристикам, а затем вычисляется итоговая двухклассовая метрика. Например, точность модели вычисляется по следующей формуле:

где ,
(коэффициент Джини)	Коэффициент Джини рассчитывается по следующей формуле:

где  — коэффициент Джини,  — FPR (False Positive Rate),   — TPR (True Positive Rate),  N — число границ cutoff по вероятности отнесения к классу.

где  — истино-положительное решение,  — ложно-положительное решение, TN — истинно-отрицательное решение, FN — ложно-отрицательное решение.
Построение доверительных интервалов для вероятности дефолта (Тест на точность калибровки на уровне портфеля)	Вероятность того, что в n наблюдениях произойдет q дефолтов в соответствии с биномиальным законом распределения, равна:

наблюдаемое число дефолтов в исследуемой выборке,
вероятность дефолта в исследуемой выборке,



где — наибольшее целое число, не превосходящее






Доверительные интервалы для вероятности дефолтов получаются делением границ доверительных интервалов для количества дефолтов на общее количество наблюдений.
Замечание: Согласно центральной предельной теореме, при
,
то есть при больших n биномиальное распределение с параметрами n и p приближается нормальным распределением с математическим ожиданием np и стандартным отклонением .
Пример: средневзвешенный (с учетом калибровочных весов) PD на выборке составляет 0,5925%, средневзвешенный DR составляет 0,5845%. Количество наблюдений в выборке – 252783.
Тогда 95% доверительный интервал может быть рассчитан следующим образом:


где   – биномиальная случайная величина с числом испытаний 252783 и вероятностью успеха ,  –  –процентный кванталь величины S.
Поскольку наблюдаемое значение DR=0,5845% находится в пределах 95% доверительного интервала, по данному тесту выставляется зеленый светофор.
Алгоритм идентификации экстремальных значений фактора	Анализ экстремальных значений проводится только для количественных факторов и заключается в определении доли значений, существенно отклоняющихся от средних величин по фактору. При этом при проведении анализа количественными факторами признаются те факторы, которые принимают более 80 уникальных значений.
Алгоритм определения экстремальных значений для факторов, близких по распределению к нормальным, основан на подходе, описанном ниже:
•	• Рассчитываются 1 и 3 квартили распределения фактора Q1 и Q3;
•	• Оценивается интерквартильный размах IQR = Q3 – Q1;
•	• Идентифицируются экстремальные значения фактора как значения, выходящие за пределы интервала ].
Если распределение фактора близко к нормальному, доля таких значений составляет около 1%. Однако в исследуемой выборке не все факторы могут иметь распределение, близкое к нормальному. Поэтому для корректного определения выбросов проводится процедура нормализации для каждого анализируемого фактора, состоящая из следующих шагов:
На первом шаге из заранее установленного списка аналитических распределений максимизацией функции правдоподобия подбирается наиболее подходящее и определяются его параметры. В список рассматриваемых аналитических распределений могут входить:
•	• Нормальное;
•	• Логнормальное;
•	• Экспоненциальное;
•	• Вейбулла;
•	• Логистическое;
•	• Гамма;
•	• Биномиальное;
•	• Пуассона.
При этом наблюдаемое распределение фактора может аппроксимироваться не только одним конкретным распределением, но и смесью распределений, в случае если фактор в существенной доле случаев принимает некоторое постоянное значение (например, 0). Под смесью распределений в данном случае понимается случайная величина следующего вида:
 
Запись выше означает, что фактор аппроксимируется случайной величиной, принимающей значение c в 10% случаев и случайное значение из нормального распределения с параметрами (0;1) в 90% случаев. Использование смесей при аппроксимации распределений позволяет добиться большей точности подгонки, а значит и более точного определения экстремальных значений.
На втором шаге для каждого значения фактора q0 рассчитывается величина значения функции вероятности подобранного теоретического распределения F(q0) = p0. Далее в соответствие каждому значению p0 ставится в соответствие значение , соответствующее накопленной вероятности p0 для стандартного нормального распределения. Таким образом производится нормализация фактора. К нормализованным значениям факторов применяется вышеописанный алгоритм определения экстремальных значений.

Процедура нормализации фактора с использованием теоретического распределения
Замечание: в случае, если распределение фактора невозможно достаточно точно аппроксимировать имеющимися теоретическими распределениями, алгоритм определения экстремальных значений применяется к ненормализованным значениям фактора.

